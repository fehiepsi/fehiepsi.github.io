<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>How to build a Grapheme-to-Phoneme (G2P) model using PyTorch | fehiepsi's blog</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://fehiepsi.github.io/blog/grapheme-to-phoneme/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="fehiepsi">
<link rel="prev" href="../rudin-complex-analysis/" title="Some solutions to Rudin's complex analysis book" type="text/html">
<link rel="next" href="../projecteuler-second50/" title="Solutions to Project Euler's second 50 problems" type="text/html">
<meta property="og:site_name" content="fehiepsi's blog">
<meta property="og:title" content="How to build a Grapheme-to-Phoneme (G2P) model using PyTorch">
<meta property="og:url" content="https://fehiepsi.github.io/blog/grapheme-to-phoneme/">
<meta property="og:description" content="introduction¶







Grapheme-to-Phoneme (G2P) model is one of the core components of a typical Text-to-Speech (TTS) system, e.g. WaveNet and Deep Voice. In this notebook, we will try to replicate the">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-06-15T20:25:53+09:00">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="G2P">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="seq2seq">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://fehiepsi.github.io/">

                <span id="blog-title">fehiepsi's blog</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive/">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>
                </li>
<li>
<a href="../../about/">About</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.ipynb" id="sourcelink">Source</a>
    </li>
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">How to build a Grapheme-to-Phoneme (G2P) model using PyTorch</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    fehiepsi
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2017-06-15T20:25:53+09:00" itemprop="datePublished" title="2017-06-15 20:25">2017-06-15 20:25</time></a></p>
                <p class="commentline">            <a href="#disqus_thread" data-disqus-identifier="cache/posts/grapheme-to-phoneme.html">Comments</a>


                    </p>
<p class="sourceline"><a href="index.ipynb" class="sourcelink">Source</a></p>

        </div>
        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="introduction">introduction<a class="anchor-link" href="#introduction">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Grapheme-to-Phoneme (G2P) model is one of the core components of a typical Text-to-Speech (TTS) system, e.g. <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WaveNet</a> and <a href="http://research.baidu.com/deep-voice-production-quality-text-speech-system-constructed-entirely-deep-neural-networks/">Deep Voice</a>. In this notebook, we will try to replicate the Encoder-decoder LSTM model from the paper <a href="https://arxiv.org/abs/1506.00196">https://arxiv.org/abs/1506.00196</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Throughout this tutorial, we will learn how to:</p>
<ul>
<li>Implement a sequence-to-sequence (seq2seq) model</li>
<li>Implement global attention into seq2seq model</li>
<li>Use beam-search decoder</li>
<li>Use Levenshtein distance to compute phoneme-error-rate (PER)</li>
<li>Use torchtext package</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="setup">setup<a class="anchor-link" href="#setup">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, we will import necessary modules. You can install PyTorch as suggested in its <a href="http://pytorch.org/">main page</a>. To install <a href="https://github.com/pytorch/text">torchtext</a>, simply call</p>
<blockquote>
<p>git install git+<a href="https://github.com/pytorch/text.git">https://github.com/pytorch/text.git</a></p>
</blockquote>
<p>Due to <a href="https://github.com/pytorch/text/pull/28">this bug</a>, it is important to update your <code>torchtext</code> to the lastest version (using the above installing command is enough).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="k">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="k">import</span> <span class="n">clip_grad_norm</span>
<span class="kn">import</span> <span class="nn">torchtext.data</span> <span class="k">as</span> <span class="nn">data</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://docs.python.org/3/library/argparse.html">argparse</a> is a default python module which is used for command-line script parsing. To run this notebook as a python script, simply comment out all the markdown cell and change the following code cell to the real <code>argparse</code> <a href="https://docs.python.org/3/howto/argparse.html">code</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">parser</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'data_path'</span><span class="p">:</span> <span class="s1">'../data/cmudict/'</span><span class="p">,</span>
    <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'max_len'</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>  <span class="c1"># max length of grapheme/phoneme sequences</span>
    <span class="s1">'beam_size'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>  <span class="c1"># size of beam for beam-search</span>
    <span class="s1">'d_embed'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>  <span class="c1"># embedding dimension</span>
    <span class="s1">'d_hidden'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>  <span class="c1"># hidden dimension</span>
    <span class="s1">'attention'</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># use attention or not</span>
    <span class="s1">'log_every'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>  <span class="c1"># number of iterations to log and validate training</span>
    <span class="s1">'lr'</span><span class="p">:</span> <span class="mf">0.007</span><span class="p">,</span>  <span class="c1"># initial learning rate</span>
    <span class="s1">'lr_decay'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>  <span class="c1"># decay lr when not observing improvement in val_loss</span>
    <span class="s1">'lr_min'</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>  <span class="c1"># stop when lr is too low</span>
    <span class="s1">'n_bad_loss'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>  <span class="c1"># number of bad val_loss before decaying</span>
    <span class="s1">'clip'</span><span class="p">:</span> <span class="mf">2.3</span><span class="p">,</span>  <span class="c1"># clip gradient, to avoid exploding gradient</span>
    <span class="s1">'cuda'</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># using gpu or not</span>
    <span class="s1">'seed'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>  <span class="c1"># initial seed</span>
    <span class="s1">'intermediate_path'</span><span class="p">:</span> <span class="s1">'../intermediate/g2p/'</span><span class="p">,</span>  <span class="c1"># path to save models</span>
<span class="p">}</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">(</span><span class="o">**</span><span class="n">parser</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we need to download the data. We will use the free <a href="https://github.com/cmusphinx/cmudict">CMUdict</a> dataset. The seed <code>5</code> is used to generate random numbers for the purpose of replicating the result. However, we still observe distinct scores for different runs of the notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">intermediate_path</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">intermediate_path</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_path</span><span class="p">):</span>
    <span class="n">URL</span> <span class="o">=</span> <span class="s2">"https://github.com/cmusphinx/cmudict/archive/master.zip"</span>
    <span class="o">!</span>wget <span class="nv">$URL</span> -O ../data/cmudict.zip
    <span class="o">!</span>unzip ../data/cmudict.zip -d ../data/
    <span class="o">!</span>mv ../data/cmudict-master <span class="nv">$args</span>.data_path

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="model">model<a class="anchor-link" href="#model">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, it is time to define our model. The following figure (taken from the paper) is a two layer Encoder-Decoder LSTM model (which is a variant of Sequence-to-Sequence model). To understand how LSTM works, we can look at the excellent blog post <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>. Each rectangle in the figure will be an <code>LSTMCell</code> in our code.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://www.researchgate.net/profile/Kaisheng_Yao/publication/277603654/figure/fig1/AS:294343429640195@1447188350615/Figure-1-An-encoder-decoder-LSTM-with-two-layers-The-encoder-LSTM-to-the-left-of-the.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before looking into the code, we need to review some PyTorch modules and functions:</p>
<ul>
<li>
<a href="http://pytorch.org/docs/nn.html#embedding">nn.Embedding</a>: a lookup table to convert indices to vectors. Theoretically, it does one-hot encoding followed by a fully connected layer (with no bias).</li>
<li>
<a href="http://pytorch.org/docs/nn.html#linear">nn.Linear</a>: nothing but a fully connected layer.</li>
<li>
<a href="http://pytorch.org/docs/nn.html#lstmcell">nn.LSTMCell</a>: a long short-term memory cell, which is mentioned above.</li>
<li>
<a href="http://pytorch.org/docs/tensors.html#torch.Tensor.size">size</a>: get the size of tensor.</li>
<li>
<a href="http://pytorch.org/docs/torch.html#torch.unsqueeze">unsqueeze</a>: create a new dimension (with size 1) for a tensor.</li>
<li>
<a href="http://pytorch.org/docs/torch.html#torch.squeeze">squeeze</a>: drop a (size 1) dimension of a tensor.</li>
<li>
<a href="http://pytorch.org/docs/torch.html#torch.chunk">chunk</a>: split a tensor along a dimension into smaller-size tensors. There is also the function <a href="http://pytorch.org/docs/torch.html#torch.split">split</a> which help us obtain the same effect.</li>
<li>
<a href="http://pytorch.org/docs/torch.html#torch.stack">stack</a>: concatenate a list of tensors along a new dimension. If we want to concatenate a long a "known" dimension, then we can use <a href="http://pytorch.org/docs/torch.html#torch.cat">cat</a> function.</li>
<li>
<a href="http://pytorch.org/docs/torch.html#torch.bmm">bmm</a>: batch matrix multiplication.</li>
<li>
<a href="http://pytorch.org/docs/torch.html#torch.index_select">index_select</a>: select values of a tensor by providing indices.</li>
<li>F.softmax, F.tanh: <a href="http://pytorch.org/docs/nn.html#non-linear-activations">non-linear activation functions</a>.</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>PyTorch's implementation of the encoder is quite straight forward. If you are not familiar with PyTorch, we recommend you to look at the <a href="http://pytorch.org/tutorials/">official tutorials</a>. It is noted that the dimension for input tensor <code>x_seq</code> is <code>seq_len x batch_size</code>. After embedding, we get a tensor of size <code>seq_len x batch_size x vector_dim</code>, not <code>batch_size x seq_len x vector_dim</code>. For us, this order of dimensions is useful for getting subsequence tensor, or an element of the sequence (for examples, to get the first element of the sequence <code>x_seq</code>, we just take <code>x_seq[0]</code>). Note that this is also the default order of input tensor for any <a href="http://pytorch.org/docs/nn.html#rnn">recurrent module</a> in PyTorch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_embed</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_embed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">d_embed</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_hidden</span> <span class="o">=</span> <span class="n">d_hidden</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_seq</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">o</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">e_seq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span>  <span class="c1"># seq x batch x dim</span>
        <span class="n">tt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span> <span class="k">if</span> <span class="n">cuda</span> <span class="k">else</span> <span class="n">torch</span>  <span class="c1"># use cuda tensor or not</span>
        <span class="c1"># create initial hidden state and initial cell state</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">e_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_hidden</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">())</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">e_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_hidden</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">())</span>
        
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">e_seq</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">e_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">e</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
            <span class="n">o</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we want to implement the decoder with attention mechanism. The article <a href="http://distill.pub/2016/augmented-rnns/">http://distill.pub/2016/augmented-rnns/</a> explains very well the idea behind the notion "attention". Here we use <strong>dot global attention</strong> from the paper <a href="https://arxiv.org/abs/1508.04025">https://arxiv.org/abs/1508.04025</a>. (The following figure is taken from this <a href="http://www.cnblogs.com/wangxiaocvpr/p/5966388.html">blog</a>.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="http://images2015.cnblogs.com/blog/670089/201610/670089-20161012111506078-902266845.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Based on https://github.com/OpenNMT/OpenNMT-py</span>

<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""Dot global attention from https://arxiv.org/abs/1508.04025"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">context</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># x: batch x dim</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">context</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># context: batch x seq x dim</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">context</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">weighted_context</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">weighted_context</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that if we do not want to add attention to the decoder, then simply set the <code>args.attention</code> to <code>False</code>. In our experiment, adding attention gave us worse result.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_embed</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_embed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">d_embed</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">d_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_hidden</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_seq</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">o</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">e_seq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x_seq</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">e_seq</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">e_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">e</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
            <span class="n">o</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">context</span><span class="p">))</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">o</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">o</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following <code>G2P</code> model is a combination of the above encoder and decoder into an end-to-end setting. We also use beam search to find the best converted phoneme sequence. To learn more about beam search, the following <a href="https://www.youtube.com/watch?v=UXW6Cs82UKo">clip</a> is helpful. In the implementation of beam search, we deal with one sequence at a time (try to find the phoneme sequence ending with token <code>eos</code>). So we have to make sure <code>batch_size == 1</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">G2P</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">G2P</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">g_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">d_embed</span><span class="p">,</span>
                               <span class="n">config</span><span class="o">.</span><span class="n">d_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">p_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">d_embed</span><span class="p">,</span>
                               <span class="n">config</span><span class="o">.</span><span class="n">d_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g_seq</span><span class="p">,</span> <span class="n">p_seq</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">o</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">g_seq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cuda</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">o</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">attention</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">p_seq</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># not generate</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">p_seq</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">g_seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>  <span class="c1"># make sure batch_size = 1</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">_generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="n">beam</span> <span class="o">=</span> <span class="n">Beam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cuda</span><span class="p">)</span>
        <span class="c1"># Make a beam_size batch.</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">beam</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>  
        <span class="n">c</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">beam</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">beam</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">context</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">context</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_len</span><span class="p">):</span>  <span class="c1"># max_len = 20</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">beam</span><span class="o">.</span><span class="n">get_current_state</span><span class="p">()</span>
            <span class="n">o</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">beam</span><span class="o">.</span><span class="n">advance</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
                <span class="k">break</span>
            <span class="n">h</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">beam</span><span class="o">.</span><span class="n">get_current_origin</span><span class="p">()))</span>
            <span class="n">c</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">beam</span><span class="o">.</span><span class="n">get_current_origin</span><span class="p">()))</span>
        <span class="n">tt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cuda</span> <span class="k">else</span> <span class="n">torch</span>
        <span class="k">return</span> <span class="n">Variable</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">beam</span><span class="o">.</span><span class="n">get_hyp</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="utils">utils<a class="anchor-link" href="#utils">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following class is the implementation of Beam search. Note that the special tokens <code>pad</code>, <code>bos</code>, <code>eos</code> have to match the corresponding tokens in phoneme dictionary.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Based on https://github.com/MaximumEntropy/Seq2Seq-PyTorch/</span>
<span class="k">class</span> <span class="nc">Beam</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">"""Ordered beam of candidate outputs."""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bos</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">eos</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">"""Initialize params."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bos</span> <span class="o">=</span> <span class="n">bos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eos</span> <span class="o">=</span> <span class="n">eos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span> <span class="k">if</span> <span class="n">cuda</span> <span class="k">else</span> <span class="n">torch</span>

        <span class="c1"># The score for each translation on the beam.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tt</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

        <span class="c1"># The backpointers at each time-step.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prevKs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># The outputs at each time-step.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nextYs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tt</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nextYs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bos</span>

    <span class="c1"># Get the outputs for the current timestep.</span>
    <span class="k">def</span> <span class="nf">get_current_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Get state of beam."""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">nextYs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Get the backpointers for the current timestep.</span>
    <span class="k">def</span> <span class="nf">get_current_origin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Get the backpointer to the beam at this step."""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prevKs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">advance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">workd_lk</span><span class="p">):</span>
        <span class="sd">"""Advance the beam."""</span>
        <span class="n">num_words</span> <span class="o">=</span> <span class="n">workd_lk</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Sum the previous scores.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prevKs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">beam_lk</span> <span class="o">=</span> <span class="n">workd_lk</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">workd_lk</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">beam_lk</span> <span class="o">=</span> <span class="n">workd_lk</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">flat_beam_lk</span> <span class="o">=</span> <span class="n">beam_lk</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">bestScores</span><span class="p">,</span> <span class="n">bestScoresId</span> <span class="o">=</span> <span class="n">flat_beam_lk</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                                                     <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scores</span> <span class="o">=</span> <span class="n">bestScores</span>

        <span class="c1"># bestScoresId is flattened beam x word array, so calculate which</span>
        <span class="c1"># word and beam each score came from</span>
        <span class="n">prev_k</span> <span class="o">=</span> <span class="n">bestScoresId</span> <span class="o">/</span> <span class="n">num_words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prevKs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_k</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nextYs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bestScoresId</span> <span class="o">-</span> <span class="n">prev_k</span> <span class="o">*</span> <span class="n">num_words</span><span class="p">)</span>
        <span class="c1"># End condition is when top-of-beam is EOS.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nextYs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">eos</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span>

    <span class="k">def</span> <span class="nf">get_hyp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="sd">"""Get hypotheses."""</span>
        <span class="n">hyp</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># print(len(self.prevKs), len(self.nextYs), len(self.attn))</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prevKs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">hyp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nextYs</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">k</span><span class="p">])</span>
            <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prevKs</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">hyp</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> is used to compute <code>phoneme-error-rate</code> (PER) for phoneme sequences (similar to <a href="https://en.wikipedia.org/wiki/Word_error_rate">word-error-rate</a> for word sequences). In the paper, there is another metric named <code>word-error-rate</code>, which is obtained by calculating the number of wrong predictions. For example, the phoneme sequence "S W AY1 G ER0 D" is a wrong prediction for the word "sweigard" (real phoneme sequence is "S W EY1 G ER0 D"). Please not to be confused between these two metrics which have the same name.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Based on https://github.com/SeanNaren/deepspeech.pytorch/blob/master/decoder.py.</span>
<span class="kn">import</span> <span class="nn">Levenshtein</span>  <span class="c1"># https://github.com/ztane/python-Levenshtein/</span>

<span class="k">def</span> <span class="nf">phoneme_error_rate</span><span class="p">(</span><span class="n">p_seq1</span><span class="p">,</span> <span class="n">p_seq2</span><span class="p">):</span>
    <span class="n">p_vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">p_seq1</span> <span class="o">+</span> <span class="n">p_seq2</span><span class="p">)</span>
    <span class="n">p2c</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">p_vocab</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p_vocab</span><span class="p">))))</span>
    <span class="n">c_seq1</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="n">p2c</span><span class="p">[</span><span class="n">p</span><span class="p">])</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_seq1</span><span class="p">]</span>
    <span class="n">c_seq2</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="n">p2c</span><span class="p">[</span><span class="n">p</span><span class="p">])</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_seq2</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">Levenshtein</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">c_seq1</span><span class="p">),</span>
                                <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">c_seq2</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">c_seq2</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following function helps to adjust learning rate for optimizer. Learning rate will be decayed if we do not see any improvement of the loss after <code>args.n_bad_loss</code> iterations.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">adjust_learning_rate</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_decay</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s1">'lr'</span><span class="p">]</span> <span class="o">*=</span> <span class="n">lr_decay</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="train">train<a class="anchor-link" href="#train">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following functions will be used to train model, validate model (using early stopping). Then we apply the final model for test data to get WER and PER (using <code>test</code> function). Finally, the <code>show</code> function will display a few examples for us.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">n_total</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">n_bad_loss</span>
    <span class="k">global</span> <span class="n">init</span><span class="p">,</span> <span class="n">best_val_loss</span><span class="p">,</span> <span class="n">stop</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">"=&gt; EPOCH </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
    <span class="n">train_iter</span><span class="o">.</span><span class="n">init_epoch</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
        <span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="n">output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">grapheme</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">phoneme</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">phoneme</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                         <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
        
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">clip</span><span class="p">,</span> <span class="s1">'inf'</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">n_total</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span>
        
        <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">log_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_loss</span> <span class="o">/=</span> <span class="n">n_total</span>
            <span class="n">val_loss</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">val_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"   % Time: </span><span class="si">{:5.0f}</span><span class="s2"> | Iteration: </span><span class="si">{:5}</span><span class="s2"> | Batch: </span><span class="si">{:4}</span><span class="s2">/</span><span class="si">{}</span><span class="s2">"</span>
                  <span class="s2">" | Train loss: </span><span class="si">{:.4f}</span><span class="s2"> | Val loss: </span><span class="si">{:.4f}</span><span class="s2">"</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">init</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">train_iter</span><span class="o">.</span><span class="n">iterations</span><span class="p">,</span>
                          <span class="nb">len</span><span class="p">(</span><span class="n">train_iter</span><span class="p">),</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">))</span>
            
            <span class="c1"># test for val_loss improvement</span>
            <span class="n">n_total</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
                <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
                <span class="n">n_bad_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">best_model</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">n_bad_loss</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">n_bad_loss</span> <span class="o">==</span> <span class="n">config</span><span class="o">.</span><span class="n">n_bad_loss</span><span class="p">:</span>
                <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
                <span class="n">n_bad_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">adjust_learning_rate</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">lr_decay</span><span class="p">)</span>
                <span class="n">new_lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'lr'</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"=&gt; Adjust learning rate to: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">new_lr</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">new_lr</span> <span class="o">&lt;</span> <span class="n">config</span><span class="o">.</span><span class="n">lr_min</span><span class="p">:</span>
                    <span class="n">stop</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>                
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">val_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">val_iter</span><span class="o">.</span><span class="n">init_epoch</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_iter</span><span class="p">:</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">grapheme</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">phoneme</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">phoneme</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">return</span> <span class="n">val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_iter</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">test_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_iter</span><span class="o">.</span><span class="n">init_epoch</span><span class="p">()</span>
    <span class="n">test_per</span> <span class="o">=</span> <span class="n">test_wer</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">test_iter</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">grapheme</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">phoneme</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="c1"># calculate per, wer here</span>
        <span class="n">per</span> <span class="o">=</span> <span class="n">phoneme_error_rate</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> 
        <span class="n">wer</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">output</span> <span class="o">!=</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">test_per</span> <span class="o">+=</span> <span class="n">per</span>  <span class="c1"># batch_size = 1</span>
        <span class="n">test_wer</span> <span class="o">+=</span> <span class="n">wer</span>
        
    <span class="n">test_per</span> <span class="o">=</span> <span class="n">test_per</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_iter</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="n">test_wer</span> <span class="o">=</span> <span class="n">test_wer</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_iter</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Phoneme error rate (PER): </span><span class="si">{:.2f}</span><span class="se">\n</span><span class="s2">Word error rate (WER): </span><span class="si">{:.2f}</span><span class="s2">"</span>
          <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_per</span><span class="p">,</span> <span class="n">test_wer</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">g_field</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">fields</span><span class="p">[</span><span class="s1">'grapheme'</span><span class="p">]</span>
    <span class="n">p_field</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">fields</span><span class="p">[</span><span class="s1">'phoneme'</span><span class="p">]</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">grapheme</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">grapheme</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">grapheme</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">1</span><span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">phoneme</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">phoneme</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"&gt; </span><span class="si">{}</span><span class="se">\n</span><span class="s2">= </span><span class="si">{}</span><span class="se">\n</span><span class="s2">&lt; </span><span class="si">{}</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">g_field</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="n">g</span><span class="p">]</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">grapheme</span><span class="p">]),</span>
        <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">p_field</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">phoneme</span><span class="p">]),</span>
        <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">p_field</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">prediction</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="prepare">prepare<a class="anchor-link" href="#prepare">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we move to the exciting part. We will create a class <code>CMUDict</code> based on <code>data.Dataset</code> from <code>torchtext</code>. It is recommended to read the <a href="https://github.com/pytorch/text/blob/master/torchtext/data.py">document</a> to understand how the <code>Dataset</code> works. The <code>splits</code> function helps us divide data into three datasets: 17/20 for training, 1/20 for validating, 2/20 for reporting final results.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The class CMUDict contains all pairs of a grapheme sequence and the corresponding phoneme sequence. Each line of the raw <a href="https://raw.githubusercontent.com/cmusphinx/cmudict/master/cmudict.dict">cmudict.dict</a> file has the form "<em>aachener AA1 K AH0 N ER0</em>". We first split it into sequences <em>aachener</em> and <em>AA1 K AH0 N ER0</em>. Each of them is a sequence of data belongs to a <em>Field</em> (for example, a sentence is a sequence of words and word is the Field of sentences). How to tokenize these sequences is implemented in the <code>tokenize</code> parameters of the definition of grapheme field and phoneme field. We also add init token and end-of-sequence token as in the original paper.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">g_field</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">init_token</span><span class="o">=</span><span class="s1">'&lt;s&gt;'</span><span class="p">,</span>
                     <span class="n">tokenize</span><span class="o">=</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">])[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">p_field</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">init_token</span><span class="o">=</span><span class="s1">'&lt;os&gt;'</span><span class="p">,</span> <span class="n">eos_token</span><span class="o">=</span><span class="s1">'&lt;/os&gt;'</span><span class="p">,</span>
                     <span class="n">tokenize</span><span class="o">=</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'#'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CMUDict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_lines</span><span class="p">,</span> <span class="n">g_field</span><span class="p">,</span> <span class="n">p_field</span><span class="p">):</span>
        <span class="n">fields</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">'grapheme'</span><span class="p">,</span> <span class="n">g_field</span><span class="p">),</span> <span class="p">(</span><span class="s1">'phoneme'</span><span class="p">,</span> <span class="n">p_field</span><span class="p">)]</span>
        <span class="n">examples</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># maybe ignore '...-1' grapheme</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data_lines</span><span class="p">:</span>
            <span class="n">grapheme</span><span class="p">,</span> <span class="n">phoneme</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">maxsplit</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">examples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Example</span><span class="o">.</span><span class="n">fromlist</span><span class="p">([</span><span class="n">grapheme</span><span class="p">,</span> <span class="n">phoneme</span><span class="p">],</span>
                                                  <span class="n">fields</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sort_key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grapheme</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CMUDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">fields</span><span class="p">)</span>
    
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">splits</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">g_field</span><span class="p">,</span> <span class="n">p_field</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">random</span>
        
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
        <span class="n">train_lines</span><span class="p">,</span> <span class="n">val_lines</span><span class="p">,</span> <span class="n">test_lines</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lines</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">val_lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">test_lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">train_lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">train_lines</span><span class="p">,</span> <span class="n">g_field</span><span class="p">,</span> <span class="n">p_field</span><span class="p">)</span>
        <span class="n">val_data</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">val_lines</span><span class="p">,</span> <span class="n">g_field</span><span class="p">,</span> <span class="n">p_field</span><span class="p">)</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">test_lines</span><span class="p">,</span> <span class="n">g_field</span><span class="p">,</span> <span class="n">p_field</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">'cmudict.dict'</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">CMUDict</span><span class="o">.</span><span class="n">splits</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">g_field</span><span class="p">,</span> <span class="n">p_field</span><span class="p">,</span>
                                                 <span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To make the dictionaries for grapheme field and phoneme field, we use the function <code>build_vocab</code>. Read its <a href="https://github.com/pytorch/text/blob/master/torchtext/data.py#L171">definition</a> to get more information.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">g_field</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>
<span class="n">p_field</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we will make <code>Iterator</code> from our datasets. These iterators will help us get data in <strong>batch</strong>. The BucketIterator will make the sequences in each batch have similar length while still preserves the randomness.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># None is current gpu</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">BucketIterator</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                 <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">val_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sort</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, it is time to create the model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="n">args</span>
<span class="n">config</span><span class="o">.</span><span class="n">g_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">g_field</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">p_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p_field</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">best_model</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">intermediate_path</span><span class="p">,</span>
                                 <span class="s2">"best_model_adagrad_attn.pth"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">G2P</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">criterion</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>  <span class="c1"># use Adagrad</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="run">run<a class="anchor-link" href="#run">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We start to train our model. It will be stopped if there is no observation on the improvement of validation loss. It take around 10 minutes for each epoch (trained on GTX 1060).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># change to True to train</span>
    <span class="n">iteration</span> <span class="o">=</span> <span class="n">n_total</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">=</span> <span class="n">n_bad_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">stop</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>=&gt; EPOCH 1
   % Time:    56 | Iteration:   100 | Batch:  100/1148 | Train loss: 1.3804 | Val loss: 0.8835
   % Time:   111 | Iteration:   200 | Batch:  200/1148 | Train loss: 0.5339 | Val loss: 0.5970
   % Time:   166 | Iteration:   300 | Batch:  300/1148 | Train loss: 0.4361 | Val loss: 0.5435
   % Time:   220 | Iteration:   400 | Batch:  400/1148 | Train loss: 0.3836 | Val loss: 0.4764
   % Time:   275 | Iteration:   500 | Batch:  500/1148 | Train loss: 0.3578 | Val loss: 0.4410
   % Time:   331 | Iteration:   600 | Batch:  600/1148 | Train loss: 0.3315 | Val loss: 0.4162
   % Time:   387 | Iteration:   700 | Batch:  700/1148 | Train loss: 0.3230 | Val loss: 0.4009
   % Time:   442 | Iteration:   800 | Batch:  800/1148 | Train loss: 0.3186 | Val loss: 0.4340
   % Time:   498 | Iteration:   900 | Batch:  900/1148 | Train loss: 0.2955 | Val loss: 0.3801
   % Time:   554 | Iteration:  1000 | Batch: 1000/1148 | Train loss: 0.2954 | Val loss: 0.3637
   % Time:   609 | Iteration:  1100 | Batch: 1100/1148 | Train loss: 0.2801 | Val loss: 0.3642
=&gt; EPOCH 2
   % Time:   664 | Iteration:  1200 | Batch:   52/1148 | Train loss: 0.2815 | Val loss: 0.3511
   % Time:   720 | Iteration:  1300 | Batch:  152/1148 | Train loss: 0.2525 | Val loss: 0.3467
   % Time:   776 | Iteration:  1400 | Batch:  252/1148 | Train loss: 0.2519 | Val loss: 0.3396
   % Time:   831 | Iteration:  1500 | Batch:  352/1148 | Train loss: 0.2548 | Val loss: 0.3322
   % Time:   887 | Iteration:  1600 | Batch:  452/1148 | Train loss: 0.2522 | Val loss: 0.3294
   % Time:   944 | Iteration:  1700 | Batch:  552/1148 | Train loss: 0.2457 | Val loss: 0.3278
   % Time:  1000 | Iteration:  1800 | Batch:  652/1148 | Train loss: 0.2460 | Val loss: 0.3224
   % Time:  1055 | Iteration:  1900 | Batch:  752/1148 | Train loss: 0.2465 | Val loss: 0.3175
   % Time:  1112 | Iteration:  2000 | Batch:  852/1148 | Train loss: 0.2321 | Val loss: 0.3157
   % Time:  1167 | Iteration:  2100 | Batch:  952/1148 | Train loss: 0.2480 | Val loss: 0.3141
   % Time:  1222 | Iteration:  2200 | Batch: 1052/1148 | Train loss: 0.2309 | Val loss: 0.3120
=&gt; EPOCH 3
   % Time:  1278 | Iteration:  2300 | Batch:    4/1148 | Train loss: 0.2322 | Val loss: 0.3077
   % Time:  1334 | Iteration:  2400 | Batch:  104/1148 | Train loss: 0.2225 | Val loss: 0.3069
   % Time:  1390 | Iteration:  2500 | Batch:  204/1148 | Train loss: 0.2131 | Val loss: 0.3050
   % Time:  1445 | Iteration:  2600 | Batch:  304/1148 | Train loss: 0.2201 | Val loss: 0.3006
   % Time:  1502 | Iteration:  2700 | Batch:  404/1148 | Train loss: 0.2241 | Val loss: 0.3019
   % Time:  1557 | Iteration:  2800 | Batch:  504/1148 | Train loss: 0.2138 | Val loss: 0.2980
   % Time:  1613 | Iteration:  2900 | Batch:  604/1148 | Train loss: 0.2181 | Val loss: 0.2967
   % Time:  1670 | Iteration:  3000 | Batch:  704/1148 | Train loss: 0.2160 | Val loss: 0.2951
   % Time:  1726 | Iteration:  3100 | Batch:  804/1148 | Train loss: 0.2170 | Val loss: 0.2919
   % Time:  1782 | Iteration:  3200 | Batch:  904/1148 | Train loss: 0.2156 | Val loss: 0.2915
   % Time:  1837 | Iteration:  3300 | Batch: 1004/1148 | Train loss: 0.2158 | Val loss: 0.2899
   % Time:  1893 | Iteration:  3400 | Batch: 1104/1148 | Train loss: 0.2117 | Val loss: 0.2880
=&gt; EPOCH 4
   % Time:  1948 | Iteration:  3500 | Batch:   56/1148 | Train loss: 0.2026 | Val loss: 0.2869
   % Time:  2003 | Iteration:  3600 | Batch:  156/1148 | Train loss: 0.2011 | Val loss: 0.2839
   % Time:  2060 | Iteration:  3700 | Batch:  256/1148 | Train loss: 0.1960 | Val loss: 0.2856
   % Time:  2117 | Iteration:  3800 | Batch:  356/1148 | Train loss: 0.2036 | Val loss: 0.2848
   % Time:  2173 | Iteration:  3900 | Batch:  456/1148 | Train loss: 0.1982 | Val loss: 0.2823
   % Time:  2228 | Iteration:  4000 | Batch:  556/1148 | Train loss: 0.1970 | Val loss: 0.2820
   % Time:  2283 | Iteration:  4100 | Batch:  656/1148 | Train loss: 0.2014 | Val loss: 0.2796
   % Time:  2338 | Iteration:  4200 | Batch:  756/1148 | Train loss: 0.2015 | Val loss: 0.2801
   % Time:  2393 | Iteration:  4300 | Batch:  856/1148 | Train loss: 0.1924 | Val loss: 0.2782
   % Time:  2450 | Iteration:  4400 | Batch:  956/1148 | Train loss: 0.1991 | Val loss: 0.2777
   % Time:  2506 | Iteration:  4500 | Batch: 1056/1148 | Train loss: 0.1971 | Val loss: 0.2774
=&gt; EPOCH 5
   % Time:  2563 | Iteration:  4600 | Batch:    8/1148 | Train loss: 0.1975 | Val loss: 0.2764
   % Time:  2619 | Iteration:  4700 | Batch:  108/1148 | Train loss: 0.1846 | Val loss: 0.2752
   % Time:  2675 | Iteration:  4800 | Batch:  208/1148 | Train loss: 0.1878 | Val loss: 0.2741
   % Time:  2731 | Iteration:  4900 | Batch:  308/1148 | Train loss: 0.1843 | Val loss: 0.2742
   % Time:  2788 | Iteration:  5000 | Batch:  408/1148 | Train loss: 0.1832 | Val loss: 0.2733
   % Time:  2843 | Iteration:  5100 | Batch:  508/1148 | Train loss: 0.1898 | Val loss: 0.2740
   % Time:  2898 | Iteration:  5200 | Batch:  608/1148 | Train loss: 0.1856 | Val loss: 0.2713
   % Time:  2955 | Iteration:  5300 | Batch:  708/1148 | Train loss: 0.1872 | Val loss: 0.2704
   % Time:  3011 | Iteration:  5400 | Batch:  808/1148 | Train loss: 0.1889 | Val loss: 0.2715
   % Time:  3068 | Iteration:  5500 | Batch:  908/1148 | Train loss: 0.1861 | Val loss: 0.2703
   % Time:  3123 | Iteration:  5600 | Batch: 1008/1148 | Train loss: 0.1837 | Val loss: 0.2700
   % Time:  3178 | Iteration:  5700 | Batch: 1108/1148 | Train loss: 0.1873 | Val loss: 0.2696
=&gt; EPOCH 6
   % Time:  3233 | Iteration:  5800 | Batch:   60/1148 | Train loss: 0.1859 | Val loss: 0.2662
   % Time:  3290 | Iteration:  5900 | Batch:  160/1148 | Train loss: 0.1745 | Val loss: 0.2677
   % Time:  3346 | Iteration:  6000 | Batch:  260/1148 | Train loss: 0.1755 | Val loss: 0.2658
   % Time:  3403 | Iteration:  6100 | Batch:  360/1148 | Train loss: 0.1725 | Val loss: 0.2678
   % Time:  3458 | Iteration:  6200 | Batch:  460/1148 | Train loss: 0.1791 | Val loss: 0.2659
   % Time:  3514 | Iteration:  6300 | Batch:  560/1148 | Train loss: 0.1762 | Val loss: 0.2655
   % Time:  3570 | Iteration:  6400 | Batch:  660/1148 | Train loss: 0.1745 | Val loss: 0.2657
   % Time:  3626 | Iteration:  6500 | Batch:  760/1148 | Train loss: 0.1739 | Val loss: 0.2637
   % Time:  3682 | Iteration:  6600 | Batch:  860/1148 | Train loss: 0.1755 | Val loss: 0.2646
   % Time:  3738 | Iteration:  6700 | Batch:  960/1148 | Train loss: 0.1766 | Val loss: 0.2641
   % Time:  3794 | Iteration:  6800 | Batch: 1060/1148 | Train loss: 0.1730 | Val loss: 0.2637
=&gt; EPOCH 7
   % Time:  3851 | Iteration:  6900 | Batch:   12/1148 | Train loss: 0.1757 | Val loss: 0.2621
   % Time:  3906 | Iteration:  7000 | Batch:  112/1148 | Train loss: 0.1631 | Val loss: 0.2614
   % Time:  3961 | Iteration:  7100 | Batch:  212/1148 | Train loss: 0.1665 | Val loss: 0.2641
   % Time:  4017 | Iteration:  7200 | Batch:  312/1148 | Train loss: 0.1683 | Val loss: 0.2616
   % Time:  4073 | Iteration:  7300 | Batch:  412/1148 | Train loss: 0.1698 | Val loss: 0.2618
   % Time:  4128 | Iteration:  7400 | Batch:  512/1148 | Train loss: 0.1679 | Val loss: 0.2605
   % Time:  4185 | Iteration:  7500 | Batch:  612/1148 | Train loss: 0.1689 | Val loss: 0.2594
   % Time:  4240 | Iteration:  7600 | Batch:  712/1148 | Train loss: 0.1673 | Val loss: 0.2597
   % Time:  4296 | Iteration:  7700 | Batch:  812/1148 | Train loss: 0.1706 | Val loss: 0.2591
   % Time:  4352 | Iteration:  7800 | Batch:  912/1148 | Train loss: 0.1658 | Val loss: 0.2585
   % Time:  4409 | Iteration:  7900 | Batch: 1012/1148 | Train loss: 0.1705 | Val loss: 0.2577
   % Time:  4465 | Iteration:  8000 | Batch: 1112/1148 | Train loss: 0.1669 | Val loss: 0.2585
=&gt; EPOCH 8
   % Time:  4521 | Iteration:  8100 | Batch:   64/1148 | Train loss: 0.1577 | Val loss: 0.2581
   % Time:  4576 | Iteration:  8200 | Batch:  164/1148 | Train loss: 0.1636 | Val loss: 0.2555
   % Time:  4633 | Iteration:  8300 | Batch:  264/1148 | Train loss: 0.1569 | Val loss: 0.2568
   % Time:  4689 | Iteration:  8400 | Batch:  364/1148 | Train loss: 0.1599 | Val loss: 0.2560
   % Time:  4745 | Iteration:  8500 | Batch:  464/1148 | Train loss: 0.1593 | Val loss: 0.2570
   % Time:  4802 | Iteration:  8600 | Batch:  564/1148 | Train loss: 0.1607 | Val loss: 0.2555
   % Time:  4858 | Iteration:  8700 | Batch:  664/1148 | Train loss: 0.1546 | Val loss: 0.2553
   % Time:  4915 | Iteration:  8800 | Batch:  764/1148 | Train loss: 0.1636 | Val loss: 0.2565
   % Time:  4971 | Iteration:  8900 | Batch:  864/1148 | Train loss: 0.1616 | Val loss: 0.2537
   % Time:  5027 | Iteration:  9000 | Batch:  964/1148 | Train loss: 0.1614 | Val loss: 0.2550
   % Time:  5083 | Iteration:  9100 | Batch: 1064/1148 | Train loss: 0.1591 | Val loss: 0.2559
=&gt; EPOCH 9
   % Time:  5140 | Iteration:  9200 | Batch:   16/1148 | Train loss: 0.1624 | Val loss: 0.2565
   % Time:  5197 | Iteration:  9300 | Batch:  116/1148 | Train loss: 0.1513 | Val loss: 0.2552
   % Time:  5253 | Iteration:  9400 | Batch:  216/1148 | Train loss: 0.1559 | Val loss: 0.2545
=&gt; Adjust learning rate to: 0.0035
   % Time:  5309 | Iteration:  9500 | Batch:  316/1148 | Train loss: 0.1471 | Val loss: 0.2519
   % Time:  5366 | Iteration:  9600 | Batch:  416/1148 | Train loss: 0.1512 | Val loss: 0.2510
   % Time:  5421 | Iteration:  9700 | Batch:  516/1148 | Train loss: 0.1508 | Val loss: 0.2504
   % Time:  5477 | Iteration:  9800 | Batch:  616/1148 | Train loss: 0.1493 | Val loss: 0.2512
   % Time:  5532 | Iteration:  9900 | Batch:  716/1148 | Train loss: 0.1542 | Val loss: 0.2500
   % Time:  5588 | Iteration: 10000 | Batch:  816/1148 | Train loss: 0.1480 | Val loss: 0.2498
   % Time:  5644 | Iteration: 10100 | Batch:  916/1148 | Train loss: 0.1494 | Val loss: 0.2494
   % Time:  5700 | Iteration: 10200 | Batch: 1016/1148 | Train loss: 0.1483 | Val loss: 0.2490
   % Time:  5755 | Iteration: 10300 | Batch: 1116/1148 | Train loss: 0.1499 | Val loss: 0.2484
=&gt; EPOCH 10
   % Time:  5811 | Iteration: 10400 | Batch:   68/1148 | Train loss: 0.1406 | Val loss: 0.2492
   % Time:  5866 | Iteration: 10500 | Batch:  168/1148 | Train loss: 0.1467 | Val loss: 0.2494
   % Time:  5922 | Iteration: 10600 | Batch:  268/1148 | Train loss: 0.1433 | Val loss: 0.2495
   % Time:  5978 | Iteration: 10700 | Batch:  368/1148 | Train loss: 0.1454 | Val loss: 0.2490
   % Time:  6033 | Iteration: 10800 | Batch:  468/1148 | Train loss: 0.1428 | Val loss: 0.2494
=&gt; Adjust learning rate to: 0.00175
   % Time:  6089 | Iteration: 10900 | Batch:  568/1148 | Train loss: 0.1447 | Val loss: 0.2482
   % Time:  6144 | Iteration: 11000 | Batch:  668/1148 | Train loss: 0.1493 | Val loss: 0.2479
   % Time:  6200 | Iteration: 11100 | Batch:  768/1148 | Train loss: 0.1445 | Val loss: 0.2479
   % Time:  6257 | Iteration: 11200 | Batch:  868/1148 | Train loss: 0.1415 | Val loss: 0.2476
   % Time:  6312 | Iteration: 11300 | Batch:  968/1148 | Train loss: 0.1436 | Val loss: 0.2469
   % Time:  6368 | Iteration: 11400 | Batch: 1068/1148 | Train loss: 0.1423 | Val loss: 0.2473
=&gt; EPOCH 11
   % Time:  6423 | Iteration: 11500 | Batch:   20/1148 | Train loss: 0.1487 | Val loss: 0.2474
   % Time:  6478 | Iteration: 11600 | Batch:  120/1148 | Train loss: 0.1435 | Val loss: 0.2478
   % Time:  6535 | Iteration: 11700 | Batch:  220/1148 | Train loss: 0.1402 | Val loss: 0.2475
   % Time:  6591 | Iteration: 11800 | Batch:  320/1148 | Train loss: 0.1378 | Val loss: 0.2476
=&gt; Adjust learning rate to: 0.000875
   % Time:  6647 | Iteration: 11900 | Batch:  420/1148 | Train loss: 0.1451 | Val loss: 0.2474
   % Time:  6702 | Iteration: 12000 | Batch:  520/1148 | Train loss: 0.1400 | Val loss: 0.2475
   % Time:  6759 | Iteration: 12100 | Batch:  620/1148 | Train loss: 0.1377 | Val loss: 0.2473
   % Time:  6814 | Iteration: 12200 | Batch:  720/1148 | Train loss: 0.1383 | Val loss: 0.2474
   % Time:  6871 | Iteration: 12300 | Batch:  820/1148 | Train loss: 0.1442 | Val loss: 0.2471
   % Time:  6927 | Iteration: 12400 | Batch:  920/1148 | Train loss: 0.1383 | Val loss: 0.2471
   % Time:  6983 | Iteration: 12500 | Batch: 1020/1148 | Train loss: 0.1407 | Val loss: 0.2472
   % Time:  7040 | Iteration: 12600 | Batch: 1120/1148 | Train loss: 0.1398 | Val loss: 0.2469
=&gt; EPOCH 12
   % Time:  7095 | Iteration: 12700 | Batch:   72/1148 | Train loss: 0.1427 | Val loss: 0.2470
   % Time:  7151 | Iteration: 12800 | Batch:  172/1148 | Train loss: 0.1362 | Val loss: 0.2473
   % Time:  7208 | Iteration: 12900 | Batch:  272/1148 | Train loss: 0.1395 | Val loss: 0.2473
   % Time:  7264 | Iteration: 13000 | Batch:  372/1148 | Train loss: 0.1396 | Val loss: 0.2474
   % Time:  7320 | Iteration: 13100 | Batch:  472/1148 | Train loss: 0.1377 | Val loss: 0.2472
=&gt; Adjust learning rate to: 0.0004375
   % Time:  7376 | Iteration: 13200 | Batch:  572/1148 | Train loss: 0.1377 | Val loss: 0.2472
   % Time:  7432 | Iteration: 13300 | Batch:  672/1148 | Train loss: 0.1415 | Val loss: 0.2470
   % Time:  7488 | Iteration: 13400 | Batch:  772/1148 | Train loss: 0.1387 | Val loss: 0.2469
   % Time:  7544 | Iteration: 13500 | Batch:  872/1148 | Train loss: 0.1402 | Val loss: 0.2470
   % Time:  7600 | Iteration: 13600 | Batch:  972/1148 | Train loss: 0.1397 | Val loss: 0.2469
   % Time:  7655 | Iteration: 13700 | Batch: 1072/1148 | Train loss: 0.1370 | Val loss: 0.2469
=&gt; EPOCH 13
   % Time:  7712 | Iteration: 13800 | Batch:   24/1148 | Train loss: 0.1405 | Val loss: 0.2469
   % Time:  7769 | Iteration: 13900 | Batch:  124/1148 | Train loss: 0.1368 | Val loss: 0.2470
   % Time:  7824 | Iteration: 14000 | Batch:  224/1148 | Train loss: 0.1343 | Val loss: 0.2470
   % Time:  7879 | Iteration: 14100 | Batch:  324/1148 | Train loss: 0.1376 | Val loss: 0.2471
   % Time:  7934 | Iteration: 14200 | Batch:  424/1148 | Train loss: 0.1400 | Val loss: 0.2472
=&gt; Adjust learning rate to: 0.00021875
   % Time:  7990 | Iteration: 14300 | Batch:  524/1148 | Train loss: 0.1347 | Val loss: 0.2471
   % Time:  8047 | Iteration: 14400 | Batch:  624/1148 | Train loss: 0.1405 | Val loss: 0.2471
   % Time:  8103 | Iteration: 14500 | Batch:  724/1148 | Train loss: 0.1392 | Val loss: 0.2471
   % Time:  8159 | Iteration: 14600 | Batch:  824/1148 | Train loss: 0.1359 | Val loss: 0.2470
   % Time:  8214 | Iteration: 14700 | Batch:  924/1148 | Train loss: 0.1396 | Val loss: 0.2470
   % Time:  8270 | Iteration: 14800 | Batch: 1024/1148 | Train loss: 0.1365 | Val loss: 0.2471
   % Time:  8327 | Iteration: 14900 | Batch: 1124/1148 | Train loss: 0.1355 | Val loss: 0.2470
=&gt; EPOCH 14
   % Time:  8383 | Iteration: 15000 | Batch:   76/1148 | Train loss: 0.1354 | Val loss: 0.2470
   % Time:  8439 | Iteration: 15100 | Batch:  176/1148 | Train loss: 0.1397 | Val loss: 0.2470
   % Time:  8495 | Iteration: 15200 | Batch:  276/1148 | Train loss: 0.1350 | Val loss: 0.2471
   % Time:  8551 | Iteration: 15300 | Batch:  376/1148 | Train loss: 0.1393 | Val loss: 0.2471
   % Time:  8607 | Iteration: 15400 | Batch:  476/1148 | Train loss: 0.1378 | Val loss: 0.2470
=&gt; Adjust learning rate to: 0.000109375
   % Time:  8663 | Iteration: 15500 | Batch:  576/1148 | Train loss: 0.1364 | Val loss: 0.2470
   % Time:  8720 | Iteration: 15600 | Batch:  676/1148 | Train loss: 0.1372 | Val loss: 0.2470
   % Time:  8776 | Iteration: 15700 | Batch:  776/1148 | Train loss: 0.1346 | Val loss: 0.2470
   % Time:  8832 | Iteration: 15800 | Batch:  876/1148 | Train loss: 0.1371 | Val loss: 0.2470
   % Time:  8888 | Iteration: 15900 | Batch:  976/1148 | Train loss: 0.1360 | Val loss: 0.2470
   % Time:  8944 | Iteration: 16000 | Batch: 1076/1148 | Train loss: 0.1378 | Val loss: 0.2470
=&gt; EPOCH 15
   % Time:  9001 | Iteration: 16100 | Batch:   28/1148 | Train loss: 0.1364 | Val loss: 0.2470
=&gt; Adjust learning rate to: 5.46875e-05
   % Time:  9057 | Iteration: 16200 | Batch:  128/1148 | Train loss: 0.1377 | Val loss: 0.2471
   % Time:  9113 | Iteration: 16300 | Batch:  228/1148 | Train loss: 0.1374 | Val loss: 0.2471
   % Time:  9170 | Iteration: 16400 | Batch:  328/1148 | Train loss: 0.1355 | Val loss: 0.2471
   % Time:  9225 | Iteration: 16500 | Batch:  428/1148 | Train loss: 0.1350 | Val loss: 0.2471
   % Time:  9281 | Iteration: 16600 | Batch:  528/1148 | Train loss: 0.1362 | Val loss: 0.2471
=&gt; Adjust learning rate to: 2.734375e-05
   % Time:  9337 | Iteration: 16700 | Batch:  628/1148 | Train loss: 0.1357 | Val loss: 0.2471
   % Time:  9394 | Iteration: 16800 | Batch:  728/1148 | Train loss: 0.1392 | Val loss: 0.2471
   % Time:  9450 | Iteration: 16900 | Batch:  828/1148 | Train loss: 0.1398 | Val loss: 0.2470
   % Time:  9505 | Iteration: 17000 | Batch:  928/1148 | Train loss: 0.1384 | Val loss: 0.2470
   % Time:  9561 | Iteration: 17100 | Batch: 1028/1148 | Train loss: 0.1374 | Val loss: 0.2470
   % Time:  9618 | Iteration: 17200 | Batch: 1128/1148 | Train loss: 0.1394 | Val loss: 0.2470
=&gt; EPOCH 16
   % Time:  9674 | Iteration: 17300 | Batch:   80/1148 | Train loss: 0.1362 | Val loss: 0.2470
   % Time:  9730 | Iteration: 17400 | Batch:  180/1148 | Train loss: 0.1383 | Val loss: 0.2470
   % Time:  9786 | Iteration: 17500 | Batch:  280/1148 | Train loss: 0.1372 | Val loss: 0.2470
   % Time:  9841 | Iteration: 17600 | Batch:  380/1148 | Train loss: 0.1346 | Val loss: 0.2470
=&gt; Adjust learning rate to: 1.3671875e-05
   % Time:  9897 | Iteration: 17700 | Batch:  480/1148 | Train loss: 0.1363 | Val loss: 0.2470
   % Time:  9952 | Iteration: 17800 | Batch:  580/1148 | Train loss: 0.1385 | Val loss: 0.2470
   % Time: 10008 | Iteration: 17900 | Batch:  680/1148 | Train loss: 0.1374 | Val loss: 0.2470
   % Time: 10063 | Iteration: 18000 | Batch:  780/1148 | Train loss: 0.1365 | Val loss: 0.2470
   % Time: 10118 | Iteration: 18100 | Batch:  880/1148 | Train loss: 0.1374 | Val loss: 0.2470
   % Time: 10173 | Iteration: 18200 | Batch:  980/1148 | Train loss: 0.1366 | Val loss: 0.2470
   % Time: 10230 | Iteration: 18300 | Batch: 1080/1148 | Train loss: 0.1376 | Val loss: 0.2470
=&gt; EPOCH 17
   % Time: 10287 | Iteration: 18400 | Batch:   32/1148 | Train loss: 0.1369 | Val loss: 0.2470
   % Time: 10343 | Iteration: 18500 | Batch:  132/1148 | Train loss: 0.1371 | Val loss: 0.2470
   % Time: 10398 | Iteration: 18600 | Batch:  232/1148 | Train loss: 0.1358 | Val loss: 0.2470
=&gt; Adjust learning rate to: 6.8359375e-06
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="test">test<a class="anchor-link" href="#test">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also want to report WER and PER. In this notebook, we use attention. Setting <code>args.attention</code> to <code>False</code> to disable it, which will improve the results.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">best_model</span><span class="p">))</span>
<span class="n">test</span><span class="p">(</span><span class="n">test_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Phoneme error rate (PER): 9.81
Word error rate (WER): 40.66
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we display 10 examples. The first line is the word, the second line is its 'true' phoneme, and the third line is our prediction.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_iter</span><span class="o">.</span><span class="n">init_epoch</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_iter</span><span class="p">):</span>
    <span class="n">show</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&gt; pacheco
= P AH0 CH EH1 K OW0
&lt; P AH0 CH EH1 K OW0

&gt; affable
= AE1 F AH0 B AH0 L
&lt; AE1 F AH0 B AH0 L

&gt; mauriello
= M AO2 R IY0 EH1 L OW0
&lt; M AO0 R IY0 EH1 L OW0

&gt; schadler
= SH EY1 D AH0 L ER0
&lt; SH AE1 D L ER0

&gt; chandon
= CH AE1 N D IH0 N
&lt; CH AE1 N D AH0 N

&gt; sines
= S AY1 N Z
&lt; S AY1 N Z

&gt; nostrums
= N AA1 S T R AH0 M Z
&lt; N AA1 S T R AH0 M Z

&gt; guandong's
= G W AA1 N D OW2 NG Z
&lt; G W AA1 N D AO1 NG Z

&gt; pry
= P R AY1
&lt; P R AY1

&gt; biddie
= B IH1 D IY0
&lt; B IH1 D IY0

&gt; manes
= M EY1 N Z
&lt; M EY1 N Z

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, the result is quite good. Happy learning!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="acknowledgement">acknowledgement<a class="anchor-link" href="#acknowledgement">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>This tutorial is done under my study with <a href="https://github.com/hminle">Hoang Le</a> and <a href="https://github.com/hoangnguyen3892">Hoang Nguyen</a>. Thank you very much for your help!</em></p>

</div>
</div>
</div>
    </div>
  </div>

    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/deep-learning/" rel="tag">deep learning</a></li>
            <li><a class="tag p-category" href="../../categories/g2p/" rel="tag">G2P</a></li>
            <li><a class="tag p-category" href="../../categories/pytorch/" rel="tag">pytorch</a></li>
            <li><a class="tag p-category" href="../../categories/seq2seq/" rel="tag">seq2seq</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../rudin-complex-analysis/" rel="prev" title="Some solutions to Rudin's complex analysis book">Previous post</a>
            </li>
            <li class="next">
                <a href="../projecteuler-second50/" rel="next" title="Solutions to Project Euler's second 50 problems">Next post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
                        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="fehiepsi-github-io",
            disqus_url="https://fehiepsi.github.io/blog/grapheme-to-phoneme/",
        disqus_title="How to build a Grapheme-to-Phoneme (G2P) model using PyTorch",
        disqus_identifier="cache/posts/grapheme-to-phoneme.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha256-ExtbCSBuYA7kq1Pz362ibde9nnsHYPt6JxuxYeZbU+c=" crossorigin="anonymous"></script><script>
                renderMathInElement(document.body,
                    {
                        
delimiters: [
    {left: "$$", right: "$$", display: true},
    {left: "\\[", right: "\\]", display: true},
    {left: "$", right: "$", display: false},
    {left: "\\(", right: "\\)", display: false}
]

                    }
                );
            </script></article><script>var disqus_shortname="fehiepsi-github-io";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
        <!--End of body content-->

        <footer id="footer"><div class="text-center">
<p>
<span class="fa-stack fa-2x">
  <a href="../../rss.xml">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-rss fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://twitter.com/fehiepsi">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-twitter fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://github.com/fehiepsi">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-github fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="https://fehiepsi.wordpress.com">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-wordpress fa-inverse fa-stack-1x"></i>
  </a>
</span>
<span class="fa-stack fa-2x">
  <a href="mailto:fehiepsi@gmail.com">
    <i class="fa fa-circle fa-stack-2x"></i>
    <i class="fa fa-envelope fa-inverse fa-stack-1x"></i>
  </a>
</span>
</p>
<p>
  Contents © 2017  <a href="mailto:fehiepsi@gmail.com">fehiepsi</a>
  —
  
<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
<img alt="Creative Commons License BY-NC-SA" style="border-width:0; margin-bottom:12px;" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a>
  —
  Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a>
</p>
</div>
            
        </footer>
</div>
</div>

            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
